{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4_OPhpWHsrNS"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "from sklearn.model_selection import train_test_split, cross_validate, KFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
        "                           f1_score, roc_auc_score, confusion_matrix,\n",
        "                           classification_report)\n",
        "from sklearn.inspection import permutation_importance\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "63dUKmaT3LY1"
      },
      "outputs": [],
      "source": [
        "\n",
        "class SalesRiskPredictor:\n",
        "    def __init__(self):\n",
        "        self.models = {\n",
        "            'rf': RandomForestClassifier(\n",
        "                n_estimators=100,\n",
        "                max_depth=5,\n",
        "                class_weight='balanced',\n",
        "                random_state=42\n",
        "            ),\n",
        "            'gb': GradientBoostingClassifier(\n",
        "                n_estimators=100,\n",
        "                max_depth=3,\n",
        "                random_state=42\n",
        "            )\n",
        "        }\n",
        "        self.scaler = StandardScaler()\n",
        "        self.feature_names = None\n",
        "\n",
        "    def create_risk_labels(self, df):\n",
        "        \"\"\"Create risk labels using multiple criteria\"\"\"\n",
        "        risk_factors = pd.DataFrame()\n",
        "\n",
        "        # 1. Opportunity decline\n",
        "        risk_factors['opp_decline'] = (\n",
        "            df['Opportunity Created (last month)'] < df['Opportunity Created (month before last)']\n",
        "        )\n",
        "\n",
        "        # 2. Activity decline (20% or more decline in calls or emails)\n",
        "        risk_factors['call_decline'] = (\n",
        "            df['Outbound Calls (last month)'] < df['Outbound Calls (month before last)'] * 0.8\n",
        "        )\n",
        "\n",
        "        risk_factors['email_decline'] = (\n",
        "            df['Personalized Outbound Emails (last month)'] <\n",
        "            df['Personalized Outbound Emails (month before last)'] * 0.8\n",
        "        )\n",
        "\n",
        "        # 3. Conversion rate decline\n",
        "        curr_calls = df['Outbound Calls (last month)'].replace(0, 1)\n",
        "        prev_calls = df['Outbound Calls (month before last)'].replace(0, 1)\n",
        "        curr_conv = df['Opportunity Created (last month)'] / curr_calls\n",
        "        prev_conv = df['Opportunity Created (month before last)'] / prev_calls\n",
        "        risk_factors['conv_decline'] = curr_conv < prev_conv * 0.8\n",
        "\n",
        "        # 4. Below median current performance\n",
        "        median_opps = df['Opportunity Created (last month)'].median()\n",
        "        risk_factors['below_median'] = df['Opportunity Created (last month)'] < median_opps\n",
        "\n",
        "        # Calculate total risk factors\n",
        "        total_risk_factors = risk_factors.sum(axis=1)\n",
        "\n",
        "        # Label as at-risk if meeting two or more risk factors\n",
        "        return (total_risk_factors >= 2).astype(int)\n",
        "\n",
        "    def prepare_features(self, df):\n",
        "        \"\"\"Prepare features for model training\"\"\"\n",
        "        features = pd.DataFrame()\n",
        "\n",
        "        # Activity Metrics\n",
        "        metrics = [\n",
        "            'Outbound Calls',\n",
        "            'Personalized Outbound Emails',\n",
        "            'Calls with Correct Contact',\n",
        "            'Demo Meeting Set',\n",
        "            'Demo Meeting Completed',\n",
        "            'Opportunity Created'\n",
        "        ]\n",
        "\n",
        "        for metric in metrics:\n",
        "            current = df[f'{metric} (last month)']\n",
        "            previous = df[f'{metric} (month before last)']\n",
        "\n",
        "            features[f'{metric}_current'] = current\n",
        "            features[f'{metric}_previous'] = previous\n",
        "\n",
        "            # Calculate changes\n",
        "            features[f'{metric}_change'] = (\n",
        "                (current - previous) / previous.replace(0, 1)\n",
        "            ).clip(-1, 1)\n",
        "\n",
        "            # Relative to median\n",
        "            median_curr = current.median()\n",
        "            if median_curr != 0:\n",
        "                features[f'{metric}_vs_median'] = (current - median_curr) / median_curr\n",
        "            else:\n",
        "                features[f'{metric}_vs_median'] = 0\n",
        "\n",
        "        # Clean data\n",
        "        features = features.replace([np.inf, -np.inf], 0)\n",
        "        features = features.fillna(0)\n",
        "\n",
        "        self.feature_names = features.columns.tolist()\n",
        "        return features\n",
        "\n",
        "    def analyze_individual_risk(self, df, employee_data, model_name='rf'):\n",
        "        \"\"\"Analyze risk factors for specific employee\"\"\"\n",
        "        # Prepare features\n",
        "        features = self.prepare_features(pd.DataFrame([employee_data]))\n",
        "        scaled_features = self.scaler.transform(features)\n",
        "\n",
        "        # Get prediction\n",
        "        model = self.models[model_name]\n",
        "        risk_proba = model.predict_proba(scaled_features)[0, 1]\n",
        "\n",
        "        # Calculate changes and percentages\n",
        "        def calc_change(current, previous):\n",
        "            if previous == 0:\n",
        "                return 0 if current == 0 else 100\n",
        "            return ((current - previous) / previous) * 100\n",
        "\n",
        "        def calc_percentile(series, value):\n",
        "            return stats.percentileofscore(series.dropna(), value)\n",
        "\n",
        "        metrics_analysis = {\n",
        "            'opportunities': {\n",
        "                'current': employee_data['Opportunity Created (last month)'],\n",
        "                'previous': employee_data['Opportunity Created (month before last)'],\n",
        "                'change_pct': calc_change(\n",
        "                    employee_data['Opportunity Created (last month)'],\n",
        "                    employee_data['Opportunity Created (month before last)']\n",
        "                )\n",
        "            },\n",
        "            'calls': {\n",
        "                'current': employee_data['Outbound Calls (last month)'],\n",
        "                'previous': employee_data['Outbound Calls (month before last)'],\n",
        "                'change_pct': calc_change(\n",
        "                    employee_data['Outbound Calls (last month)'],\n",
        "                    employee_data['Outbound Calls (month before last)']\n",
        "                )\n",
        "            },\n",
        "            'emails': {\n",
        "                'current': employee_data['Personalized Outbound Emails (last month)'],\n",
        "                'previous': employee_data['Personalized Outbound Emails (month before last)'],\n",
        "                'change_pct': calc_change(\n",
        "                    employee_data['Personalized Outbound Emails (last month)'],\n",
        "                    employee_data['Personalized Outbound Emails (month before last)']\n",
        "                )\n",
        "            }\n",
        "        }\n",
        "\n",
        "        # Peer comparisons\n",
        "        peer_metrics = {\n",
        "            'opportunities': {\n",
        "                'employee': employee_data['Opportunity Created (last month)'],\n",
        "                'team_median': df['Opportunity Created (last month)'].median(),\n",
        "                'percentile': calc_percentile(\n",
        "                    df['Opportunity Created (last month)'],\n",
        "                    employee_data['Opportunity Created (last month)']\n",
        "                )\n",
        "            },\n",
        "            'calls': {\n",
        "                'employee': employee_data['Outbound Calls (last month)'],\n",
        "                'team_median': df['Outbound Calls (last month)'].median(),\n",
        "                'percentile': calc_percentile(\n",
        "                    df['Outbound Calls (last month)'],\n",
        "                    employee_data['Outbound Calls (last month)']\n",
        "                )\n",
        "            },\n",
        "            'emails': {\n",
        "                'employee': employee_data['Personalized Outbound Emails (last month)'],\n",
        "                'team_median': df['Personalized Outbound Emails (last month)'].median(),\n",
        "                'percentile': calc_percentile(\n",
        "                    df['Personalized Outbound Emails (last month)'],\n",
        "                    employee_data['Personalized Outbound Emails (last month)']\n",
        "                )\n",
        "            }\n",
        "        }\n",
        "\n",
        "        # Feature importance specific to this employee\n",
        "        feature_importance = pd.DataFrame({\n",
        "            'feature': self.feature_names,\n",
        "            'importance': model.feature_importances_,\n",
        "            'value': features.iloc[0].values\n",
        "        })\n",
        "\n",
        "        return {\n",
        "            'name': employee_data['user_name'],\n",
        "            'risk_score': risk_proba,\n",
        "            'risk_level': 'High' if risk_proba >= 0.7 else 'Medium' if risk_proba >= 0.4 else 'Low',\n",
        "            'metrics': metrics_analysis,\n",
        "            'peer_comparison': peer_metrics,\n",
        "            'feature_importance': feature_importance.sort_values('importance', ascending=False).to_dict('records')\n",
        "        }\n",
        "\n",
        "    def train_evaluate_models(self, df):\n",
        "        \"\"\"Train and evaluate risk prediction models with cross validation\"\"\"\n",
        "        X = self.prepare_features(df)\n",
        "        y = self.create_risk_labels(df)\n",
        "\n",
        "        # Print class distribution\n",
        "        class_counts = np.bincount(y)\n",
        "        print(f\"\\nClass distribution:\")\n",
        "        print(f\"Not at risk: {class_counts[0]}\")\n",
        "        print(f\"At risk: {class_counts[1]}\")\n",
        "\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            X, y, test_size=0.2, random_state=42, stratify=y\n",
        "        )\n",
        "\n",
        "        X_train_scaled = self.scaler.fit_transform(X_train)\n",
        "        X_test_scaled = self.scaler.transform(X_test)\n",
        "\n",
        "        results = {}\n",
        "        for name, model in self.models.items():\n",
        "            # Cross-validation\n",
        "            cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "            cv_results = cross_validate(\n",
        "                model, X_train_scaled, y_train,\n",
        "                cv=cv,\n",
        "                scoring=['accuracy', 'precision', 'recall', 'f1', 'roc_auc'],\n",
        "                return_train_score=True\n",
        "            )\n",
        "\n",
        "            # Train final model\n",
        "            model.fit(X_train_scaled, y_train)\n",
        "\n",
        "            # Feature importance\n",
        "            importance = pd.DataFrame({\n",
        "                'feature': self.feature_names,\n",
        "                'importance': model.feature_importances_\n",
        "            }).sort_values('importance', ascending=False)\n",
        "\n",
        "            results[name] = {\n",
        "                'cv_results': {\n",
        "                    metric: {\n",
        "                        'mean': cv_results[f'test_{metric}'].mean(),\n",
        "                        'std': cv_results[f'test_{metric}'].std()\n",
        "                    } for metric in ['accuracy', 'precision', 'recall', 'f1', 'roc_auc']\n",
        "                },\n",
        "                'feature_importance': {\n",
        "                    'features': importance.to_dict('records')\n",
        "                }\n",
        "            }\n",
        "\n",
        "        return results\n",
        "\n",
        "    def predict_risk(self, df, model_name='rf'):\n",
        "        \"\"\"Generate risk predictions\"\"\"\n",
        "        X = self.prepare_features(df)\n",
        "        X_scaled = self.scaler.transform(X)\n",
        "\n",
        "        model = self.models[model_name]\n",
        "        risk_proba = model.predict_proba(X_scaled)[:, 1]\n",
        "\n",
        "        return pd.DataFrame({\n",
        "            'user_name': df['user_name'],\n",
        "            'risk_score': risk_proba,\n",
        "            'risk_level': np.where(risk_proba >= 0.7, 'High',\n",
        "                                 np.where(risk_proba >= 0.4, 'Medium', 'Low'))\n",
        "        })\n",
        "\n",
        "def format_insights(analysis):\n",
        "    \"\"\"Format analysis insights for display\"\"\"\n",
        "    metrics = analysis['metrics']\n",
        "    peers = analysis['peer_comparison']\n",
        "    insights = []\n",
        "\n",
        "    # Performance changes\n",
        "    for metric, data in metrics.items():\n",
        "        if data['change_pct'] < -20:\n",
        "            insights.append(f\"{metric.title()} declined by {abs(data['change_pct']):.1f}% \"\n",
        "                          f\"(from {data['previous']} to {data['current']})\")\n",
        "\n",
        "    # Peer comparisons\n",
        "    for metric, data in peers.items():\n",
        "        if data['percentile'] < 25:\n",
        "            insights.append(f\"{metric.title()} in bottom quartile \"\n",
        "                          f\"({data['employee']} vs team median {data['team_median']:.1f})\")\n",
        "\n",
        "    return insights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xBKMKyAw3Puf",
        "outputId": "fad9184e-22aa-48a9-8ac0-3db5af77c787"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading data...\n",
            "Training models...\n",
            "\n",
            "Class distribution:\n",
            "Not at risk: 42\n",
            "At risk: 8\n",
            "Generating predictions...\n",
            "\n",
            "Saved 6 high-risk representatives to 'high_risk_reps.csv'\n",
            "\n",
            "Model Performance (Random Forest):\n",
            "accuracy: 0.925 (±0.061)\n",
            "precision: 0.400 (±0.490)\n",
            "recall: 0.300 (±0.400)\n",
            "f1: 0.333 (±0.422)\n",
            "roc_auc: nan (±nan)\n",
            "\n",
            "Top 5 Important Features:\n",
            "Outbound Calls_change: 0.282\n",
            "Demo Meeting Completed_change: 0.094\n",
            "Outbound Calls_vs_median: 0.076\n",
            "Calls with Correct Contact_current: 0.066\n",
            "Outbound Calls_current: 0.054\n",
            "\n",
            "Risk Level Distribution:\n",
            "risk_level\n",
            "Low       42\n",
            "High       6\n",
            "Medium     2\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Risk Level Percentages:\n",
            "risk_level\n",
            "Low       84.0%\n",
            "High      12.0%\n",
            "Medium     4.0%\n",
            "Name: proportion, dtype: object\n",
            "\n",
            "=== Detailed Risk Analysis ===\n",
            "Risk Factor:  High\n",
            "\n",
            "Example High Risk Employee:\n",
            "Name: Lisa Park\n",
            "Risk Score: 0.688\n",
            "\n",
            "Key Risk Factors:\n",
            "- Calls declined by 20.9% (from 153 to 121)\n",
            "- Calls in bottom quartile (121 vs team median 205.5)\n",
            "\n",
            "Top Contributing Features:\n",
            "- Outbound Calls_change: 0.282\n",
            "- Demo Meeting Completed_change: 0.094\n",
            "- Outbound Calls_vs_median: 0.076\n",
            "\n",
            "Peer Comparison Summary:\n",
            "- Opportunities: 0 (Team Median: 0.5, Percentile: 26.0)\n",
            "- Calls: 121 (Team Median: 205.5, Percentile: 15.0)\n",
            "- Emails: 76 (Team Median: 98.0, Percentile: 30.0)\n",
            "--------------------------------------------------\n",
            "Risk Factor:  Medium\n",
            "\n",
            "Example Medium Risk Employee:\n",
            "Name: Emma Wilson\n",
            "Risk Score: 0.609\n",
            "\n",
            "Key Risk Factors:\n",
            "- Calls declined by 21.6% (from 171 to 134)\n",
            "- Calls in bottom quartile (134 vs team median 205.5)\n",
            "\n",
            "Top Contributing Features:\n",
            "- Outbound Calls_change: 0.282\n",
            "- Demo Meeting Completed_change: 0.094\n",
            "- Outbound Calls_vs_median: 0.076\n",
            "\n",
            "Peer Comparison Summary:\n",
            "- Opportunities: 0 (Team Median: 0.5, Percentile: 26.0)\n",
            "- Calls: 134 (Team Median: 205.5, Percentile: 22.0)\n",
            "- Emails: 92 (Team Median: 98.0, Percentile: 46.0)\n",
            "--------------------------------------------------\n",
            "Risk Factor:  Low\n",
            "\n",
            "Example Low Risk Employee:\n",
            "Name: Marcus Chen\n",
            "Risk Score: 0.050\n",
            "\n",
            "Key Risk Factors:\n",
            "\n",
            "Top Contributing Features:\n",
            "- Outbound Calls_change: 0.282\n",
            "- Demo Meeting Completed_change: 0.094\n",
            "- Outbound Calls_vs_median: 0.076\n",
            "\n",
            "Peer Comparison Summary:\n",
            "- Opportunities: 0 (Team Median: 0.5, Percentile: 26.0)\n",
            "- Calls: 309 (Team Median: 205.5, Percentile: 96.0)\n",
            "- Emails: 104 (Team Median: 98.0, Percentile: 56.0)\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "def main():\n",
        "    try:\n",
        "        # Load and process data\n",
        "        print(\"Loading data...\")\n",
        "        df = pd.read_csv('monthly_report_expanded.csv')\n",
        "\n",
        "        predictor = SalesRiskPredictor()\n",
        "\n",
        "        # Train models and generate predictions\n",
        "        print(\"Training models...\")\n",
        "        model_results = predictor.train_evaluate_models(df)\n",
        "\n",
        "        print(\"Generating predictions...\")\n",
        "        risk_predictions = predictor.predict_risk(df)\n",
        "\n",
        "        # Save high-risk reps to CSV\n",
        "        high_risk_reps = risk_predictions[risk_predictions['risk_level'] == 'High']\n",
        "        high_risk_reps.to_csv('high_risk_reps.csv', index=False)\n",
        "        print(f\"\\nSaved {len(high_risk_reps)} high-risk representatives to 'high_risk_reps.csv'\")\n",
        "\n",
        "        # Display model performance metrics\n",
        "        print(\"\\nModel Performance (Random Forest):\")\n",
        "        rf_results = model_results['rf']\n",
        "        for metric, values in rf_results['cv_results'].items():\n",
        "            print(f\"{metric}: {values['mean']:.3f} (±{values['std']:.3f})\")\n",
        "\n",
        "        # Display feature importance\n",
        "        print(\"\\nTop 5 Important Features:\")\n",
        "        for feature in rf_results['feature_importance']['features'][:5]:\n",
        "            print(f\"{feature['feature']}: {feature['importance']:.3f}\")\n",
        "\n",
        "        # Display risk distribution\n",
        "        print(f\"\\nRisk Level Distribution:\")\n",
        "        print(risk_predictions['risk_level'].value_counts())\n",
        "        print(\"\\nRisk Level Percentages:\")\n",
        "        print(risk_predictions['risk_level'].value_counts(normalize=True).mul(100).round(1).astype(str) + '%')\n",
        "\n",
        "        # Get examples from each risk category\n",
        "        risk_levels = {'High': None, 'Medium': None, 'Low': None}\n",
        "        for level in risk_levels:\n",
        "\n",
        "            mask = risk_predictions['risk_level'] == level\n",
        "            if mask.any():\n",
        "                employee = risk_predictions[mask].iloc[0]\n",
        "                emp_data = df[df['user_name'] == employee['user_name']].iloc[0]\n",
        "                analysis = predictor.analyze_individual_risk(df, emp_data)\n",
        "                risk_levels[level] = analysis\n",
        "\n",
        "      \n",
        "        print(\"\\n=== Detailed Risk Analysis ===\")\n",
        "        for level, analysis in risk_levels.items():\n",
        "            if analysis:\n",
        "                print(\"Risk Factor: \", level)\n",
        "                print(f\"\\nExample {level} Risk Employee:\")\n",
        "                print(f\"Name: {analysis['name']}\")\n",
        "                print(f\"Risk Score: {analysis['risk_score']:.3f}\")\n",
        "\n",
        "                print(\"\\nKey Risk Factors:\")\n",
        "                insights = format_insights(analysis)\n",
        "                for insight in insights:\n",
        "                    print(f\"- {insight}\")\n",
        "\n",
        "                print(\"\\nTop Contributing Features:\")\n",
        "                for feature in analysis['feature_importance'][:3]:\n",
        "                    print(f\"- {feature['feature']}: {feature['importance']:.3f}\")\n",
        "\n",
        "                print(\"\\nPeer Comparison Summary:\")\n",
        "                for metric, data in analysis['peer_comparison'].items():\n",
        "                    print(f\"- {metric.title()}: {data['employee']} \"\n",
        "                          f\"(Team Median: {data['team_median']:.1f}, \"\n",
        "                          f\"Percentile: {data['percentile']:.1f})\")\n",
        "                print(\"-\" * 50)\n",
        "\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in analysis: {str(e)}\")\n",
        "        raise\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
